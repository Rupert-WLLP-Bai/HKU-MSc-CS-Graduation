\chapter{Experiment} % Main chapter title

\label{ChapterX} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Experiment Settings}

\subsection{Datasets and Evaluation Metrics}
\sloppy
We conduct extensive experiments on four large-scale public datasets: Arts\_Crafts\_and\_Sewing (Arts), Grocery\_and\_Gourmet\_Food (Grocery), Office\_Products (Office), and Patio\_Lawn\_and\_Garden (Garden). These datasets include both user interaction data and rich item textual content collected from Amazon \cite{amazon_data}. Each dataset is split into training, validation, and test sets using an 8/1/1 ratio. Following previous work \cite{CTR_work1, CTR_work2}, we employ two widely-used metrics to evaluate performance: AUC and LogLoss. As noted in CTR studies \cite{CTR_study1}, an improvement of 0.001 in AUC (\(\uparrow\)) or Log Loss (\(\downarrow\)) is considered significant, as it can lead to a substantial increase in online revenue.

\subsection{Base CTR Methods and Baselines}
We implement the MSD-CTR based on two foundational CTR methods: DCNv2 \cite{DCNv2} and DeepFM \cite{DeepFM}. Our model is compared against the following competitive methods:
\begin{itemize}
    \item \textbf{Concat:} Directly integrates the semantic embeddings as new features and concatenates them with the traditional CTR features.
    \item \textbf{CTRL:} Employs a contrastive learning strategy to incorporate semantic embeddings \cite{CTRL}.
    \item \textbf{TIGER:} Uses an RQVAE to generate semantic IDs from textual information for subsequent recommendation tasks \cite{TIGER}.
    \item \textbf{MOC:} An enhanced method based on TIGER that utilizes a mixture-of-codes strategy to mitigate information loss \cite{MOC}.
    \item \textbf{VQRec:} A discrete ID-based method that adopts vector-quantized codes using optimized product quantization \cite{VQRec}.
\end{itemize}

\subsection{Implementation Details}
For a fair comparison, we generate \( H \) new features from the semantic embeddings for all baselines (except CTRL) to ensure the same feature count. We set the number of semantic embeddings to 4, i.e., \( H = 4 \). For item textual information, we collect the item title, description, and reviews provided by buyers. We utilize BERT \cite{BERT} as the backbone PLM to obtain semantic embeddings, with the PLM embedding dimension set to \( D_{PLM} = 768 \). For the DSTopic, we set the total number of topics \( K = 100 \) and adopt pre-trained word embeddings generated by BERT, with \( D_{TM} = 768 \). The dimension of the topic embeddings is set to 64. We use the Adam optimizer with a batch size of 2048, a learning rate of 0.001, and a weight decay of \( 1 \times 10^{-6} \) for training DSTopic. For the CTR models, we use the Adam optimizer with a batch size of 2048, a learning rate of 0.001, and a weight decay of \( 1 \times 10^{-6} \). The embedding size for all other experiments is set to 10, i.e., \( D = 10 \). All experiments apply early stopping based on validation AUC with patience of 3. Each experiment is repeated three times with different random initializations. All experiments are conducted on a single NVIDIA GeForce RTX 3090.

%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------

\section{Overall Performance}
\input{Figures/Chapter4/Table1}
\input{Figures/Chapter4/Table2}

We compare the overall performance of different models, with the results presented in Table \ref{tab:performance_comparison}. From the results, we can draw the following observations:
\begin{itemize}
    \item In most scenarios, incorporating semantic information is beneficial for CTR prediction and leads to performance improvements. However, this is not universally true; in some cases, such as CTRL on the Arts and Grocery datasets, the contrastive learning approach adversely affects the learning of the original features.
    \item Our method outperforms the baselines in most settings, and in other scenarios, it demonstrates competitive performance compared to state-of-the-art (SOTA) methods. These results highlight the effectiveness of disentangling multi-faceted knowledge.
    \item Discrete ID-based methods demonstrate superior performance compared to the naive concat method. However, due to issues such as information loss \cite{MOC} and entangled semantic spaces (as detailed in Section 4.3), these methods perform worse than the proposed approach.
\end{itemize}

%----------------------------------------------------------------------------------------
%	SECTION 3
%----------------------------------------------------------------------------------------

\section{Qualitative Study}
\input{Figures/Chapter4/Table3}

\subsection{Study on the Learned Topic Model}
We randomly selected learned topics from each view and summarized the keywords using ChatGPT-4o1 for the Grocery dataset. The summaries and corresponding topic words are presented in Table \ref{tab:learned_topics}. Our analysis reveals distinct and disentangled views within the learned topics. For instance, View 0 emphasizes Healthy Snacks and highlights Beverages and Drinks. In contrast, View 1 focuses on Product Quality, addressing consumer expectations and essential cooking ingredients.

\subsection{Visualization of Learned Semantic Embeddings}
We utilize t-SNE \cite{TSNE} to visualize the disentangled topic embeddings $[z^{(1)}_i, z^{(2)}_i, \dots, z^{(H)}_i]$ in DSTopic (a), the learned semantic embeddings $[\tilde{t}^{(1)}_i, \tilde{t}^{(2)}_i, \dots, \tilde{t}^{(H)}_i]$ in TopicDRL (c), and the embeddings from compared methods (b, d-f) using DCNv2, as shown in Figure~\ref{fig:visualization}. We have the following observations:
\begin{itemize}
    \item DSTopic has successfully learned the disentangled multi-view embeddings, which are situated in distinct embedding spaces.
    \item TopicDRL helps CTR prediction by learning disentangled semantic embeddings, demonstrating an improvement over the naive Concat method.
    \item Due to the adoption of RQVAE, TIGERâ€™s first view occupies a different semantic space from the others; however, as a result of information loss, the remaining views become entangled in the same semantic space.
    \item The MoC and VQRec methods fail to learn disentangled semantic embeddings, which limits their overall performance.
\end{itemize}
